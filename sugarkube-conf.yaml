log_level: none
#json_logs: false
#no_color: true

# Dynamically searches for terraform tfvars files based on the current stack provider and various properties of the
# stack (e.g. name, region, etc.) as well as any generated files. All files found are prepended by `-var-file`
tf_patterns: &tf_patterns
  tf_params: >-
    {{ mapPrintF "terraform_%s/.*defaults\\.tfvars$" (listString .stack.provider) | findFiles .kapp.cacheRoot | mapPrintF "-var-file %s" | uniq | join " " | trim }}
    {{ mapPrintF (mapPrintF "terraform_%s/.*%%s\\.tfvars$" (listString .stack.provider) | join "") (.sugarkube.defaultVars | removeEmpty) | findFiles .kapp.cacheRoot | mapPrintF "-var-file %s" | uniq | join " " | trim }}
    {{ mapPrintF "terraform_%s/.*_generated_.*\\.tfvars$" (listString .stack.provider) | findFiles .kapp.cacheRoot | mapPrintF "-var-file %s" | uniq | join " " | trim }}

# Search for parameters dynamically. The `findFiles` function takes a list of
# file name patterns and a starting directory to search from. It then recursively
# searches for a single file matching the pattern. If one (and only one) is found,
# it's returned in the result array. Patterns that don't match any files are
# filtered out.
#
# The `.sugarkube.defaultVars` variable is a list populated at runtime containing (in
# order of precedence: provider, account, profile, cluster, region.
#
# So these scary looking things search for a values.yaml file in the kapp cache directory, as well as
# `values-<provider/account/profile/etc>.yaml` and prepends '-f' ready to be passed as options to helm.
helm_patterns: &helm_patterns
  helm_params: >-
    {{ listString "/values\\.yaml$" | findFiles .kapp.cacheRoot | mapPrintF "-f %s" | uniq | last | join " " | trim }}
    {{ mapPrintF "/values-%s\\.yaml$" (.sugarkube.defaultVars | removeEmpty) | findFiles .kapp.cacheRoot | mapPrintF "-f %s" | uniq | join " " | trim }}
    {{ listString "/_generated_.*\\.yaml$" | findFiles .kapp.cacheRoot | mapPrintF "-f %s" | uniq | join " " | trim }}

programs:
  helm:
    vars:
      kubeconfig: "{{ .kubeconfig }}"
      namespace: "{{ .kapp.id }}"
      release: "{{ .kapp.id }}"
      kube_context: "{{ .kube_context }}"
      <<: *helm_patterns

    args:
      make:
        install:
          helm-params: "{{ .kapps.vars.helm_params }}"
        delete:
          helm-params: "{{ .kapps.vars.helm_params }}"

    run_units:
      vars:
        helm: helm        # path to the helm binary to run. This allows version pinning if you have multiple versions of helm on your machine.
        run_helm: true    # none of these units will be run for a kapp if this is false because of the associated condition
      working_dir: "{{ .kapp.cacheRoot }}"       # directory to use as the working directory
      conditions:       # all must be true for any units to be run
        - "{{ .kapp.vars.run_helm }}"
      plan_install:
        - name: helm-lint
          command: |
            KUBECONFIG={{ .kapp.vars.kubeconfig }} {{ .kapp.vars.helm }} lint \
              --kube-context={{ .kapp.vars.kube_context }} \
              --namespace={{ .kapp.vars.namespace }} . {{ .kapp.vars.helm_params }}
      apply_install:
        - name: helm-install
          command: |
            KUBECONFIG={{ .kapp.vars.kubeconfig }} {{ .kapp.vars.helm }} upgrade \
              --kube-context={{ .kapp.vars.kube_context }} \
              --tiller-namespace={{ .kapp.vars.tiller_namespace }} \
              --wait \
              --install \
              --recreate-pods \
              --timeout 600 \
              --namespace={{ .kapp.vars.namespace }} \
              {{ .kapp.vars.release }} . {{ .kapp.vars.helm_params }}
          merge_priority: 5         # install helm charts *after* running terraform
      apply_delete:
        - name: helm-delete
          command: |
            KUBECONFIG={{ .kapp.vars.kubeconfig }} {{ .kapp.vars.helm }} delete \
              --kube-context={{ .kapp.vars.kube_context }} \
              --tiller-namespace={{ .kapp.vars.tiller_namespace }} \
              --purge \
              {{ .kapp.vars.release }}
          merge_priority: 0         # delete helm charts *before* running terraform

  kubectl:
    vars:
      kubeconfig: "{{ .kubeconfig }}"
      kube_context: "{{ .kube_context }}"
      namespace: "{{ .kapp.id }}"

  aws:
    vars:
      region: "{{ .stack.region }}"

  terraform:
    vars:
      region: "{{ .stack.region }}"
      project: "{{ .project }}"
      <<: *tf_patterns

    args:
      make:
        install:
          tf-patterns: "{{ .kapp.vars.tf_patterns }}"
        delete:
          tf-patterns: "{{ .kapp.vars.tf_patterns }}"
        output:
          tf-patterns: "{{ .kapp.vars.tf_patterns }}"

    run_units:
      vars:
        run_terraform: true    # none of these units will be run for a kapp if this is false because of the associated condition
        terraform: terraform   # path to the terraform binary to run. This allows version pinning if you have multiple versions of terraform on your machine.
        terraform_dir: terraform_{{ .stack.provider }}
        tf_output_path: _generated_terraform_output.json
        tf_plan_path: _generated_plan.tfplan

      working_dir: "{{ .kapp.cacheRoot }}/{{ .kapp.vars.terraform_dir }}"       # directory to use as the working directory
      conditions:       # all must be true for any units to be run
        - "{{ .kapp.vars.run_terraform }}"
        - "{{ eq len(findFiles .kapp.vars.terraform_dir) 1 }}"          # won't run these if there's no terraform_<provider> directory (e.g. for local providers)
      plan_install:
        - name: tf-init
          command: "{{ .kapp.vars.terraform }} init"
          conditions:       # additional conditions for this specific step to be run. These must all be truthy for the command to be executed.
          # only run if terraform hasn't already initialised (i.e. no .terraform directory exists)
          - "{{ eq len(findFiles \"{{ .kapp.cacheRoot }}/{{ .kapp.vars.terraform_dir }}/.terraform\") 0 }}"
        - name: tf-format
          command: "{{ .kapp.vars.terraform }} fmt"
        - name: tf-validate
          command: "{{ .kapp.vars.terraform }} validate {{ .kapp.vars.tf_params }}"
        - name: tf-plan
          command: "{{ .kapp.vars.terraform }} plan -refresh=true -out {{ .kapp.vars.tf_plan_path }} {{ .kapp.vars.tf_params }}"
      apply_install:
        - name: tf-apply
          command: "{{ .kapp.vars.terraform }} apply {{ .kapp.vars.tf_plan_path }}"
          merge_priority: 0         # apply terraform *before* installing a helm chart
      apply_delete:
        - call: tf-init       # call the tf-init step defined under `plan_install`
        - name: tf-destroy
          command: "{{ .kapp.vars.terraform }} destroy -auto-approve {{ .kapp.vars.tf_params }}"
          merge_priority: 5         # delete terraform *after* deleting a helm chart
      output:
        - call: tf-init       # call the tf-init step defined under `plan_install`
        - name: tf-output
          command: "{{ .kapp.vars.terraform }} output -json > {{ .kapp.vars.tf_output_path }}"

# globally defined run units will be used as defaults for each program
run_units:
  clean:
    - command: "rm {{ .kapp.cacheRoot }}/*.log"
    - command: "rm {{ .kapp.cacheRoot }}/*.err"
    - command: "find {{ .kapp.cacheRoot }} -name '_generated_*' -type f -delete"
    - command: "find {{ .kapp.cacheRoot }} -name '_generated_*' -type d -exec rm -r {} ';'"
